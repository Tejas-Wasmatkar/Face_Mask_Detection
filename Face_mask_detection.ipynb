{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required imports\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "from imutils.video import VideoStream\n",
    "import numpy as np\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining No. of Epochs, batch size\n",
    "\n",
    "DIRECTORY = \"C:/Users/TEJAS/Desktop/mask detection/other/Face-Mask-Detection-master/dataset\"\n",
    "CATEGORIES = [\"with_mask\", \"without_mask\"]\n",
    "\n",
    "\n",
    "INIT_LR = 1e-4\n",
    "EPOCHS = 20\n",
    "BS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting list of data\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(DIRECTORY, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_path = os.path.join(path, img)\n",
    "        image = load_img(img_path, target_size=(224, 224))\n",
    "        image = img_to_array(image)\n",
    "        image = preprocess_input(image)\n",
    "\n",
    "        data.append(image)\n",
    "        labels.append(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing one hot encoding on labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train- Test Split\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
    "test_size=0.20, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating Image data\n",
    "aug = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "# Implement CNN for training model\n",
    "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
    "    input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(2, activation=\"softmax\")(headModel)\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "    metrics=[\"accuracy\"])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "95/95 [==============================] - 133s 1s/step - loss: 0.6160 - accuracy: 0.7184 - val_loss: 0.1500 - val_accuracy: 0.9752\n",
      "Epoch 2/20\n",
      "95/95 [==============================] - 122s 1s/step - loss: 0.1739 - accuracy: 0.9504 - val_loss: 0.0772 - val_accuracy: 0.9883\n",
      "Epoch 3/20\n",
      "95/95 [==============================] - 119s 1s/step - loss: 0.1097 - accuracy: 0.9707 - val_loss: 0.0587 - val_accuracy: 0.9909\n",
      "Epoch 4/20\n",
      "95/95 [==============================] - 121s 1s/step - loss: 0.0806 - accuracy: 0.9801 - val_loss: 0.0462 - val_accuracy: 0.9935\n",
      "Epoch 5/20\n",
      "95/95 [==============================] - 127s 1s/step - loss: 0.0692 - accuracy: 0.9805 - val_loss: 0.0403 - val_accuracy: 0.9935\n",
      "Epoch 6/20\n",
      "95/95 [==============================] - 136s 1s/step - loss: 0.0596 - accuracy: 0.9837 - val_loss: 0.0392 - val_accuracy: 0.9922\n",
      "Epoch 7/20\n",
      "95/95 [==============================] - 124s 1s/step - loss: 0.0581 - accuracy: 0.9843 - val_loss: 0.0371 - val_accuracy: 0.9896\n",
      "Epoch 8/20\n",
      "95/95 [==============================] - 127s 1s/step - loss: 0.0467 - accuracy: 0.9848 - val_loss: 0.0334 - val_accuracy: 0.9935\n",
      "Epoch 9/20\n",
      "95/95 [==============================] - 117s 1s/step - loss: 0.0471 - accuracy: 0.9872 - val_loss: 0.0327 - val_accuracy: 0.9935\n",
      "Epoch 10/20\n",
      "95/95 [==============================] - 120s 1s/step - loss: 0.0469 - accuracy: 0.9850 - val_loss: 0.0300 - val_accuracy: 0.9935\n",
      "Epoch 11/20\n",
      "95/95 [==============================] - 118s 1s/step - loss: 0.0476 - accuracy: 0.9866 - val_loss: 0.0336 - val_accuracy: 0.9909\n",
      "Epoch 12/20\n",
      "95/95 [==============================] - 123s 1s/step - loss: 0.0346 - accuracy: 0.9885 - val_loss: 0.0280 - val_accuracy: 0.9935\n",
      "Epoch 13/20\n",
      "95/95 [==============================] - 130s 1s/step - loss: 0.0381 - accuracy: 0.9896 - val_loss: 0.0273 - val_accuracy: 0.9935\n",
      "Epoch 14/20\n",
      "95/95 [==============================] - 133s 1s/step - loss: 0.0485 - accuracy: 0.9855 - val_loss: 0.0277 - val_accuracy: 0.9935\n",
      "Epoch 15/20\n",
      "95/95 [==============================] - 128s 1s/step - loss: 0.0360 - accuracy: 0.9881 - val_loss: 0.0288 - val_accuracy: 0.9935\n",
      "Epoch 16/20\n",
      "95/95 [==============================] - 131s 1s/step - loss: 0.0261 - accuracy: 0.9931 - val_loss: 0.0314 - val_accuracy: 0.9922\n",
      "Epoch 17/20\n",
      "95/95 [==============================] - 120s 1s/step - loss: 0.0281 - accuracy: 0.9902 - val_loss: 0.0269 - val_accuracy: 0.9922\n",
      "Epoch 18/20\n",
      "95/95 [==============================] - 125s 1s/step - loss: 0.0290 - accuracy: 0.9920 - val_loss: 0.0287 - val_accuracy: 0.9935\n",
      "Epoch 19/20\n",
      "95/95 [==============================] - 134s 1s/step - loss: 0.0249 - accuracy: 0.9906 - val_loss: 0.0260 - val_accuracy: 0.9922\n",
      "Epoch 20/20\n",
      "95/95 [==============================] - 122s 1s/step - loss: 0.0298 - accuracy: 0.9891 - val_loss: 0.0252 - val_accuracy: 0.9935\n"
     ]
    }
   ],
   "source": [
    "# fitting the model \n",
    "H = model.fit(\n",
    "\taug.flow(trainX, trainY, batch_size=BS),\n",
    "\tsteps_per_epoch=len(trainX) // BS,\n",
    "\tvalidation_data=(testX, testY),\n",
    "\tvalidation_steps=len(testX) // BS,\n",
    "\tepochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n"
     ]
    }
   ],
   "source": [
    "# Prediction on test set\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predIdxs = model.predict(testX, batch_size=BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predIdxs = np.argmax(predIdxs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   with_mask       0.99      0.99      0.99       383\n",
      "without_mask       0.99      0.99      0.99       384\n",
      "\n",
      "    accuracy                           0.99       767\n",
      "   macro avg       0.99      0.99      0.99       767\n",
      "weighted avg       0.99      0.99      0.99       767\n",
      "\n",
      "[INFO] saving mask detector model...\n"
     ]
    }
   ],
   "source": [
    "# classisfication report\n",
    "print(classification_report(testY.argmax(axis=1), predIdxs,\n",
    "     target_names=lb.classes_))\n",
    "\n",
    "print(\"[INFO] saving mask detector model...\")\n",
    "model.save(\"mask_detector.model\", save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting training loss & accuracy\n",
    "N = EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecting mask with a function\n",
    "def detect_and_predict_mask(frame, faceNet, maskNet):\n",
    "    # grab the dimensions of the frame and then construct a blob\n",
    "    # from it\n",
    "    (h, w) = frame.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1.0, (224, 224),\n",
    "        (104.0, 177.0, 123.0))\n",
    "\n",
    "    # pass the blob through the network and obtain the face detections\n",
    "    faceNet.setInput(blob)\n",
    "    detections = faceNet.forward()\n",
    "    print(detections.shape)\n",
    "\n",
    "    # initialize our list of faces, their corresponding locations,\n",
    "    # and the list of predictions from our face mask network\n",
    "    faces = []\n",
    "    locs = []\n",
    "    preds = []\n",
    "\n",
    "    # loop over the detections\n",
    "    for i in range(0, detections.shape[2]):\n",
    "        # extract the confidence (i.e., probability) associated with\n",
    "        # the detection\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "\n",
    "        # filter out weak detections by ensuring the confidence is\n",
    "        # greater than the minimum confidence\n",
    "        if confidence > 0.5:\n",
    "           # compute the (x, y)-coordinates of the bounding box for\n",
    "           # the object\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "            # ensure the bounding boxes fall within the dimensions of\n",
    "            # the frame\n",
    "            (startX, startY) = (max(0, startX), max(0, startY))\n",
    "            (endX, endY) = (min(w - 1, endX), min(h - 1, endY))\n",
    "\n",
    "            # extract the face ROI, convert it from BGR to RGB channel\n",
    "            # ordering, resize it to 224x224, and preprocess it\n",
    "            face = frame[startY:endY, startX:endX]\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "            face = cv2.resize(face, (224, 224))\n",
    "            face = img_to_array(face)\n",
    "            face = preprocess_input(face)\n",
    "\n",
    "            # add the face and bounding boxes to their respective\n",
    "            # lists\n",
    "            faces.append(face)\n",
    "            locs.append((startX, startY, endX, endY))\n",
    "\n",
    "    # only make a predictions if at least one face was detected\n",
    "    if len(faces) > 0:\n",
    "       # for faster inference we'll make batch predictions on *all*\n",
    "       # faces at the same time rather than one-by-one predictions\n",
    "       # in the above `for` loop\n",
    "       faces = np.array(faces, dtype=\"float32\")\n",
    "    preds = maskNet.predict(faces, batch_size=32)\n",
    "\n",
    "    # return a 2-tuple of the face locations and their corresponding\n",
    "    # locations\n",
    "    return (locs, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] starting video stream...\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n",
      "(1, 1, 200, 7)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-5d8546db9d4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m# detect faces in the frame and determine if they are wearing a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m# face mask or not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[1;33m(\u001b[0m\u001b[0mlocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetect_and_predict_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfaceNet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaskNet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# loop over the detected face locations and their corresponding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-8a1f082bb8a6>\u001b[0m in \u001b[0;36mdetect_and_predict_mask\u001b[1;34m(frame, faceNet, maskNet)\u001b[0m\n\u001b[0;32m     56\u001b[0m        \u001b[1;31m# in the above `for` loop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m        \u001b[0mfaces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfaces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"float32\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaskNet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfaces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;31m# return a 2-tuple of the face locations and their corresponding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1596\u001b[0m                         '. Consider setting it to AutoShardPolicy.DATA.')\n\u001b[0;32m   1597\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1598\u001b[1;33m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[0;32m   1599\u001b[0m           \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1600\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[0;32m   1097\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_steps_per_execution_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msteps_per_execution\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1099\u001b[1;33m     \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1100\u001b[0m     self._adapter = adapter_cls(\n\u001b[0;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m   \u001b[1;34m\"\"\"Selects a data adapter than can handle a given x and y.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 958\u001b[1;33m   \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcls\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mALL_ADAPTER_CLS\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcan_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    959\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0madapter_cls\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m     \u001b[1;31m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m   \u001b[1;34m\"\"\"Selects a data adapter than can handle a given x and y.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 958\u001b[1;33m   \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcls\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mALL_ADAPTER_CLS\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcan_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    959\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0madapter_cls\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m     \u001b[1;31m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mcan_handle\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    610\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcan_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m     \u001b[0mhandles_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mListsOfScalarsDataAdapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_list_of_scalars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    613\u001b[0m     \u001b[0mhandles_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_is_list_of_scalars\u001b[1;34m(inp)\u001b[0m\n\u001b[0;32m    621\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 623\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mListsOfScalarsDataAdapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_list_of_scalars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    624\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Loding model from disk\n",
    "prototxtPath = \"C:/Users/TEJAS/Desktop/Face Mask Detection/face_detector/deploy.prototxt\"\n",
    "weightsPath = \"C:/Users/TEJAS/Desktop/Face Mask Detection/face_detector/res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "faceNet = cv2.dnn.readNet(prototxtPath, weightsPath)\n",
    "maskNet = load_model(\"mask_detector.model\")\n",
    "\n",
    "print(\"[INFO] starting video stream...\")\n",
    "vs = VideoStream(src=0).start()\n",
    "while True:\n",
    "    # grab the frame from the threaded video stream and resize it\n",
    "    # to have a maximum width of 400 pixels\n",
    "    frame = vs.read()\n",
    "    frame = imutils.resize(frame, width=400)\n",
    "\n",
    "    # detect faces in the frame and determine if they are wearing a\n",
    "    # face mask or not\n",
    "    (locs, preds) = detect_and_predict_mask(frame, faceNet, maskNet)\n",
    "\n",
    "    # loop over the detected face locations and their corresponding\n",
    "    # locations\n",
    "    for (box, pred) in zip(locs, preds):\n",
    "        # unpack the bounding box and predictions\n",
    "        (startX, startY, endX, endY) = box\n",
    "        (mask, withoutMask) = pred\n",
    "\n",
    "        # determine the class label and color we'll use to draw\n",
    "        # the bounding box and text\n",
    "        label = \"Mask\" if mask > withoutMask else \"No Mask\"\n",
    "        color = (0, 255, 0) if label == \"Mask\" else (0, 0, 255)\n",
    "\n",
    "        # include the probability in the label\n",
    "        label = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
    "\n",
    "        # display the label and bounding box rectangle on the output\n",
    "        # frame\n",
    "        cv2.putText(frame, label, (startX, startY - 10),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
    "        cv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)\n",
    "\n",
    "   # show the output frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "   # if the `q` key was pressed, break from the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# do a bit of cleanup\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
